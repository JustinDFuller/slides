# Deconstructing Go Concurrency Concepts

## üëã Intro 

I'm Justin Fuller, a Software Engineer at The New York Times. 

I'm a self-taught developer with about 5 years of experience.

I've worked professionally with Java, Coldfusion, JavaScript, C# .NET, and Go. 

So far, Go is my favorite!

## ‚ö†Ô∏è Warning ‚ö†Ô∏è

I am not an expert on the internals of the Go Runtime or even concurrent programming.

I have been writing code with these tools for several years.

## Then why am I giving this presentation?

I want to demonstrate a learning style that I have found useful.

* Have you ever taken a car engine apart? Radio?
* You learn by investigating how it works, how all the parts fit together.
* This is typically done on things you are already familiar with.
* Gives you the ability to maintain and debug when something goes wrong.
* They are no longer a "black box".

## What is a Concurrency Concept?

* Deconstruct implies concrete, concept implies abstract.
* A concurrency concept is the _idea_ behind a tool commonly used in concurrent programming.
* Go has implementations of concepts.
* Examples
  * WaitGroup
  * Mutex
  * Pool
  * Channel

## How do you deconstruct a concept?

1. Show
    * Demonstrate the need for the concept with a broken example.

2. Define
    * Agree on a clear explanation of what an implementation of the concept would accomplish.

3. Use
    * If an implementation already exists, start with that.

4. Create
    * After using any existing implementations, write and use your own.

## First, a little code.

.play 0-naive-concurrency.go /func main/,

Ideally this would output something like:
```
Saw i = 9
Saw i = 1
Saw i = 6
Saw i = 7
Saw i = 8
Saw i = 3
Saw i = 2
Saw i = 4
Saw i = 5
Saw i = 0
Done
```

## Our First Concept

The current code doesn't work as expected. All the logs should be printed before "done".

We need a concurrency tool that tracks the number of in-progress operations, then waits for all operations to complete.

We will accomplish this with a __WaitGroup__.

## sync.WaitGroup

Now that we've defined what we need, we use an existing implementation of WaitGroup from Go's `sync` package.

.play 1-waitgroup.go /func main/,

## Custom WaitGroup

We have defined what a waitgroup should do. We have used an existing implementation. It's time to create our own.

.play 2-customwaitgroup.go /type WaitGroup/,

How would you fill this in?

## Filling in the logic 

Could it really be this simple? üôå

.play 3-race-condition-waitgroup.go /type WaitGroup/,

## Race Detector üïµÔ∏è‚Äç‚ôÄÔ∏è

```

‚ùØ go run -race 3-race-condition-waitgroup.go
Saw i = 0
Saw i = 1
==================
WARNING: DATA RACE
Read at 0x00c000136008 by goroutine 7:
  main.(*WaitGroup).Done()
      /Users/justin/code/presentation/3-race-condition-waitgroup.go:29 +0x3a
  main.main.func1()
      /Users/justin/code/presentation/3-race-condition-waitgroup.go:13 +0x123

Previous write at 0x00c000136008 by main goroutine:
  main.(*WaitGroup).Add()
      /Users/justin/code/presentation/3-race-condition-waitgroup.go:25 +0x86
  main.main()
      /Users/justin/code/presentation/3-race-condition-waitgroup.go:9 +0x67

Goroutine 7 (running) created at:
  main.main()
      /Users/justin/code/presentation/3-race-condition-waitgroup.go:10 +0xbd
==================
```

## Demonstrating the race condition

Looping 1000 times, instead of 10, shows the race condition.

.play 4-demonstrate-race-condition.go /func main/,

## Preventing Race Conditions

It's time to define a new concept before we deconstruct it.

We need to prevent _conflicting access_ to the WaitGroup's counter. To accomplish this we will use a lock, or __Mutex__.

The goal of a mutex is to prevent conflicting access to data, ensuring that updates happen as expected.

## Lock It Down üîí

We've defined a Mutex, now we use an existing implementation. Again, we start with Go's `sync` package.

.play 5-mutex.go /type WaitGroup/,

## What does the race detector say?

```

‚ùØ go run -race 5-mutex.go
Saw i = 0
Added an extra
Saw i = 1
Saw i = 2
Saw i = 3
Saw i = 4
Saw i = 5
Saw i = 6
Saw i = 7
Saw i = 8
Saw i = 9
Saw i = 10
-- skip a few logs --
Saw i = 98
Saw i = 99
Done
```

## Build Your Own

Just like before, we start with an empty shell that fulfills sync.Mutex's signature, but not behavior. The race condition reappears.

.play 6-custom-mutex.go /type Mutex/,

How would you fill this in?

## Filling It In

.play 7-naive-mutex.go /type Mutex/,

## A new concept

This broken example shows that it's time for a new concept to aid us.

We need a mechanism to lock a memory location _outside of our code_.

## Atomic

It turns out such a thing already exists in the Go standard library's Atomic package.

From the documentation:

> Package atomic provides low-level atomic memory primitives useful for __implementing synchronization algorithms__.

> These functions require great care to be used correctly. Except for special, low-level applications, 
synchronization is better done with channels or the facilities of the sync package. 

> Share memory by communicating; don't communicate by sharing memory.

## Without a race condition.

.play 8-atomic-mutex.go /const/,

## What is it doing?

Again, from the docs:

```

The compare-and-swap operation, implemented by the CompareAndSwapT functions, 
is the atomic equivalent of:

if *addr == old {
	*addr = new
	return true
}
return false
```

## Can we go any lower?

So far we have gone progressively "lower", first using, then writing our own WaitGroup, then Mutex.

We can't go any lower because the implementations of atomic are written in assembly.

.code 9-atomic.s

This code obtains a lock at the processor level.

## Is that really all there is? (Again)

This code is far simpler than the Go standard library code. This can't be all there is.

A little googling and reading through the Go source leads to a few scenarios I didn't think about:

* Starvation
* FIFO - First In, First Out
* Performance - In `Lock` the loop just spins forever.

## Starvation?

* The process cannot get the resource it needs to complete a task.
* One goroutine is greedy and gets a lock far more often than others.

Is that happening in my Waitgroup?

```
> go run 10-starvation.go
WaitGroup.Wait() got the lock 17253 times

> GOMAXPROCS=1 go run 10-starvation.go
WaitGroup.Wait() got the lock 6153599 times
```

Wait() got the goroutine, 6,153,599 times. The other goroutines got it 220 times! There's definitely unfairness happening.

## Running with GOMAXPROCS

GOMAXPROCS determines the number of processes Go will use. Setting this to 1 will only allow 1 goroutine to run at a time.

This helps us see what happens when the WaitGroup methods, like Wait and Defer, have to compete for processing resources.

## Classic Go Unfairness Example

.code 10-sync-starvation.go /done :=/,


## Results

With Regular sync.Mutex
```
‚ùØ go run 10-sync-starvation.go
Slow Got 100 Fast Got 10
```

With My Custom Mutex
```
‚ùØ go run 10-sync-starvation.go
Slow Got 21 Fast Got 10
```

GOMAXPROCS=1 sync.Mutex
```
‚ùØ GOMAXPROCS=1 go run 10-sync-starvation.go
Slow Got 103 Fast Got 10
```

GOMAXPROCS=1 custom Mutex
```
‚ùØ GOMAXPROCS=1 go run 10-sync-starvation.go
It never finished, even after several minutes!
```

## Hand Off

Right now the Goroutine that holds the Mutex lock is able to hold it potentially forever.

We need a way to let other Goroutines have a chance to get the Mutex lock.

## Handling 1 Process

.play 11-custom-mutex-starvation.go /Mutex\) Unlock/,

```
‚ùØ GOMAXPROCS=1 go run 11-custom-mutex-starvation.go
Slow got 11 Fast got 10
```

From the docs:

> Gosched yields the processor, allowing other goroutines to run. It does not suspend the current goroutine, so execution resumes automatically.

This mimics what the sync.Mutex does, with one exception. The sync.Mutex only does this when in "starvation mode".

## Back to the original example

Here's what happened when we ran the original WaitGroup with 1 process:
```
> go run 10-starvation.go
WaitGroup.Wait() got the lock 17253 times

> GOMAXPROCS=1 go run 10-starvation.go
WaitGroup.Wait() got the lock 6153599 times
```

Now here's what happens:
```
‚ùØ go run 12-waitgroup-mutex-starvation.go
WaitGroup.Wait() got the lock 2 times.

‚ùØ GOMAXPROCS=1 go run 12-waitgroup-mutex-starvation.go
WaitGroup.Wait() got the lock 2 times.
```

It's definitely more fair!

## Summary & Next Steps

There's a lot more left. To keep learning I will:

* Try to improve correctness. Is my Mutex acting in a FIFO manner, should it?
* Try to improve performance. Can I detect when I need to use `Gosched`?
* Try to improve performance again. Is an endless loop really the best way?

## Your Next Steps

You can do this for anything you're interested in learning. Turn the "black box" mystery into something
understandable by building your own.

* JavaScript Developers: write your own Promise or Array.
* Data Analysts: write your own database.
* Backend Developers: write your own http server.

Good candidates are anything with an existing implementation that you can compare to.

